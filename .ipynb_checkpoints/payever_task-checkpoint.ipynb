{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d438ac-9f69-4e19-98a2-ddf2bd05d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5677a74-7112-4d34-8997-3a7e626ff908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Faker in d:\\programfiles\\miniconda\\lib\\site-packages (25.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in d:\\programfiles\\miniconda\\lib\\site-packages (from Faker) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programfiles\\miniconda\\lib\\site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf72287-6031-4e38-afbd-431dd06f731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                                     description  \\\n",
      "0           Tent Under               Waterproof tent for remain people   \n",
      "1   Running Shoes Wait  Lightweight running shoes with result material   \n",
      "2  Yoga Mat Understand      Eco-friendly yoga mat with discuss surface   \n",
      "3    Dining Table Deal    Modern dining table with seating for medical   \n",
      "4    Blender President           High-speed blender with drug settings   \n",
      "\n",
      "     price           category  \n",
      "0  1308.44  Sports & Outdoors  \n",
      "1   641.22  Sports & Outdoors  \n",
      "2   863.17  Sports & Outdoors  \n",
      "3  1403.64          Furniture  \n",
      "4  1276.71    Home Appliances  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Define product categories\n",
    "categories = [\"Electronics\", \"Personal Care\", \"Sports & Outdoors\", \"Home Appliances\", \"Furniture\"]\n",
    "\n",
    "# Define sample product names and descriptions by category\n",
    "product_samples = {\n",
    "    \"Electronics\": [\n",
    "        {\"name\": \"Laptop\", \"description\": \"High-performance laptop with {}-inch display\"},\n",
    "        {\"name\": \"Smartphone\", \"description\": \"Latest model smartphone with {} battery\"},\n",
    "        {\"name\": \"Headphones\", \"description\": \"Noise-cancelling {} headphones\"},\n",
    "        {\"name\": \"Tablet\", \"description\": \"Portable tablet with {}-inch screen\"},\n",
    "        {\"name\": \"Smartwatch\", \"description\": \"Wearable smartwatch with {} features\"}\n",
    "    ],\n",
    "    \"Personal Care\": [\n",
    "        {\"name\": \"Toothbrush\", \"description\": \"Rechargeable electric toothbrush with {} modes\"},\n",
    "        {\"name\": \"Hair Dryer\", \"description\": \"Professional hair dryer with {} settings\"},\n",
    "        {\"name\": \"Electric Shaver\", \"description\": \"Rechargeable electric shaver with {} blades\"},\n",
    "        {\"name\": \"Facial Cleanser\", \"description\": \"Electric facial cleanser with {} speed settings\"},\n",
    "        {\"name\": \"Hair Straightener\", \"description\": \"Ceramic hair straightener with {} temperature settings\"}\n",
    "    ],\n",
    "    \"Sports & Outdoors\": [\n",
    "        {\"name\": \"Yoga Mat\", \"description\": \"Eco-friendly yoga mat with {} surface\"},\n",
    "        {\"name\": \"Running Shoes\", \"description\": \"Lightweight running shoes with {} material\"},\n",
    "        {\"name\": \"Tent\", \"description\": \"Waterproof tent for {} people\"},\n",
    "        {\"name\": \"Fitness Tracker\", \"description\": \"Wearable fitness tracker with {} features\"},\n",
    "        {\"name\": \"Bicycle\", \"description\": \"Mountain bicycle with {} gears\"}\n",
    "    ],\n",
    "    \"Home Appliances\": [\n",
    "        {\"name\": \"Blender\", \"description\": \"High-speed blender with {} settings\"},\n",
    "        {\"name\": \"Coffee Maker\", \"description\": \"Programmable coffee maker with {} capacity\"},\n",
    "        {\"name\": \"Vacuum Cleaner\", \"description\": \"Bagless vacuum cleaner with {} suction power\"},\n",
    "        {\"name\": \"Microwave Oven\", \"description\": \"Countertop microwave oven with {} presets\"},\n",
    "        {\"name\": \"Air Purifier\", \"description\": \"HEPA air purifier with {} speed settings\"}\n",
    "    ],\n",
    "    \"Furniture\": [\n",
    "        {\"name\": \"Desk Chair\", \"description\": \"Ergonomic desk chair with {} support\"},\n",
    "        {\"name\": \"Dining Table\", \"description\": \"Modern dining table with seating for {}\"},\n",
    "        {\"name\": \"Sofa\", \"description\": \"Comfortable sofa with {} cushions\"},\n",
    "        {\"name\": \"Bookshelf\", \"description\": \"Wooden bookshelf with {} shelves\"},\n",
    "        {\"name\": \"Bed Frame\", \"description\": \"King-size bed frame with {} design\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Function to generate a random product\n",
    "def generate_random_product():\n",
    "    category = random.choice(categories)\n",
    "    product_sample = random.choice(product_samples[category])\n",
    "    name = f\"{product_sample['name']} {fake.word().capitalize()}\"\n",
    "    description = product_sample[\"description\"].format(fake.word())\n",
    "    price = round(random.uniform(10.0, 2000.0), 2)\n",
    "    return {\"name\": name, \"description\": description, \"price\": price, \"category\": category}\n",
    "\n",
    "# Generate 10,000 random products\n",
    "products = [generate_random_product() for _ in range(10000)]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV for further use\n",
    "df.to_csv(\"dummy_products.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293ce57d-5818-486b-bc5a-ea10530c641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>Air Purifier Do</td>\n",
       "      <td>HEPA air purifier with fall speed settings</td>\n",
       "      <td>1009.97</td>\n",
       "      <td>Home Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>Microwave Oven No</td>\n",
       "      <td>Countertop microwave oven with quality presets</td>\n",
       "      <td>1904.44</td>\n",
       "      <td>Home Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>Electric Shaver Their</td>\n",
       "      <td>Rechargeable electric shaver with leave blades</td>\n",
       "      <td>1093.36</td>\n",
       "      <td>Personal Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>Smartwatch Money</td>\n",
       "      <td>Wearable smartwatch with line features</td>\n",
       "      <td>838.64</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>Yoga Mat Sound</td>\n",
       "      <td>Eco-friendly yoga mat with machine surface</td>\n",
       "      <td>1449.76</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                                     description  \\\n",
       "4341        Air Purifier Do      HEPA air purifier with fall speed settings   \n",
       "7579      Microwave Oven No  Countertop microwave oven with quality presets   \n",
       "7705  Electric Shaver Their  Rechargeable electric shaver with leave blades   \n",
       "3815       Smartwatch Money          Wearable smartwatch with line features   \n",
       "2290         Yoga Mat Sound      Eco-friendly yoga mat with machine surface   \n",
       "\n",
       "        price           category  \n",
       "4341  1009.97    Home Appliances  \n",
       "7579  1904.44    Home Appliances  \n",
       "7705  1093.36      Personal Care  \n",
       "3815   838.64        Electronics  \n",
       "2290  1449.76  Sports & Outdoors  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c314b8a-2061-465a-8ce2-fd733ba67a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to lowercase\n",
    "#removing special characters, punctuation\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "\n",
    "df['name'] = df['name'].apply(clean_text)\n",
    "df['description'] = df['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf4c646-2503-449d-b78a-29b5f603eecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\programfiles\\miniconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\programfiles\\miniconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\programfiles\\miniconda\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\programfiles\\miniconda\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in d:\\programfiles\\miniconda\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\programfiles\\miniconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f70119c-7eb7-48c8-af16-51717e37e613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tokenizing data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['name'] = df['name'].apply(word_tokenize)\n",
    "df['description'] = df['description'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd1a324-2893-4df9-b2f5-7b81144e60e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tent, under]</td>\n",
       "      <td>[waterproof, tent, for, remain, people]</td>\n",
       "      <td>1308.44</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[running, shoes, wait]</td>\n",
       "      <td>[lightweight, running, shoes, with, result, ma...</td>\n",
       "      <td>641.22</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[yoga, mat, understand]</td>\n",
       "      <td>[ecofriendly, yoga, mat, with, discuss, surface]</td>\n",
       "      <td>863.17</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dining, table, deal]</td>\n",
       "      <td>[modern, dining, table, with, seating, for, me...</td>\n",
       "      <td>1403.64</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[blender, president]</td>\n",
       "      <td>[highspeed, blender, with, drug, settings]</td>\n",
       "      <td>1276.71</td>\n",
       "      <td>Home Appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                        description  \\\n",
       "0            [tent, under]            [waterproof, tent, for, remain, people]   \n",
       "1   [running, shoes, wait]  [lightweight, running, shoes, with, result, ma...   \n",
       "2  [yoga, mat, understand]   [ecofriendly, yoga, mat, with, discuss, surface]   \n",
       "3    [dining, table, deal]  [modern, dining, table, with, seating, for, me...   \n",
       "4     [blender, president]         [highspeed, blender, with, drug, settings]   \n",
       "\n",
       "     price           category  \n",
       "0  1308.44  Sports & Outdoors  \n",
       "1   641.22  Sports & Outdoors  \n",
       "2   863.17  Sports & Outdoors  \n",
       "3  1403.64          Furniture  \n",
       "4  1276.71    Home Appliances  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6e017f-0ee4-4846-9f92-b5ef747c84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "df['name'] = df['name'].apply(remove_stop_words)\n",
    "df['description'] = df['description'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e2bbca-731d-4b57-ba8e-0c4d141df4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tent]</td>\n",
       "      <td>[waterproof, tent, remain, people]</td>\n",
       "      <td>1308.44</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[running, shoes, wait]</td>\n",
       "      <td>[lightweight, running, shoes, result, material]</td>\n",
       "      <td>641.22</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[yoga, mat, understand]</td>\n",
       "      <td>[ecofriendly, yoga, mat, discuss, surface]</td>\n",
       "      <td>863.17</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dining, table, deal]</td>\n",
       "      <td>[modern, dining, table, seating, medical]</td>\n",
       "      <td>1403.64</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[blender, president]</td>\n",
       "      <td>[highspeed, blender, drug, settings]</td>\n",
       "      <td>1276.71</td>\n",
       "      <td>Home Appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                      description  \\\n",
       "0                   [tent]               [waterproof, tent, remain, people]   \n",
       "1   [running, shoes, wait]  [lightweight, running, shoes, result, material]   \n",
       "2  [yoga, mat, understand]       [ecofriendly, yoga, mat, discuss, surface]   \n",
       "3    [dining, table, deal]        [modern, dining, table, seating, medical]   \n",
       "4     [blender, president]             [highspeed, blender, drug, settings]   \n",
       "\n",
       "     price           category  \n",
       "0  1308.44  Sports & Outdoors  \n",
       "1   641.22  Sports & Outdoors  \n",
       "2   863.17  Sports & Outdoors  \n",
       "3  1403.64          Furniture  \n",
       "4  1276.71    Home Appliances  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae3539c-24a1-4d58-abdc-55c1a6c9d9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#lemmatization - converting words to their root word or base form\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "df['name'] = df['name'].apply(lemmatize_tokens)\n",
    "df['description'] = df['description'].apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26346d9b-2a6f-4ea7-87d9-cb03d72e5fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tent]</td>\n",
       "      <td>[waterproof, tent, remain, people]</td>\n",
       "      <td>1308.44</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[running, shoe, wait]</td>\n",
       "      <td>[lightweight, running, shoe, result, material]</td>\n",
       "      <td>641.22</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[yoga, mat, understand]</td>\n",
       "      <td>[ecofriendly, yoga, mat, discus, surface]</td>\n",
       "      <td>863.17</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dining, table, deal]</td>\n",
       "      <td>[modern, dining, table, seating, medical]</td>\n",
       "      <td>1403.64</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[blender, president]</td>\n",
       "      <td>[highspeed, blender, drug, setting]</td>\n",
       "      <td>1276.71</td>\n",
       "      <td>Home Appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                     description  \\\n",
       "0                   [tent]              [waterproof, tent, remain, people]   \n",
       "1    [running, shoe, wait]  [lightweight, running, shoe, result, material]   \n",
       "2  [yoga, mat, understand]       [ecofriendly, yoga, mat, discus, surface]   \n",
       "3    [dining, table, deal]       [modern, dining, table, seating, medical]   \n",
       "4     [blender, president]             [highspeed, blender, drug, setting]   \n",
       "\n",
       "     price           category  \n",
       "0  1308.44  Sports & Outdoors  \n",
       "1   641.22  Sports & Outdoors  \n",
       "2   863.17  Sports & Outdoors  \n",
       "3  1403.64          Furniture  \n",
       "4  1276.71    Home Appliances  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8fe7f4f-1aec-4e28-a507-977418dc7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "df['name'] = df['name'].astype(str)\n",
    "df['description'] = df['description'].astype(str)\n",
    "\n",
    "# Concatenate text data from both columns\n",
    "all_text = (df['name'].apply(lambda x: ' '.join(x)) + ' ' +\n",
    "            df['description'].apply(lambda x: ' '.join(x)))\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "\n",
    "# Convert text data in each column to sequences of integers\n",
    "sequences_col1 = tokenizer.texts_to_sequences(df['name'].apply(lambda x: ' '.join(x)))\n",
    "sequences_col2 = tokenizer.texts_to_sequences(df['description'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "max_length = max(max(len(seq) for seq in sequences_col1), max(len(seq) for seq in sequences_col2))\n",
    "padded_sequences_col1 = pad_sequences(sequences_col1, maxlen=max_length, padding='post')\n",
    "padded_sequences_col2 = pad_sequences(sequences_col2, maxlen=max_length, padding='post')\n",
    "\n",
    "# Replace original text data in the columns with padded sequences\n",
    "df['name'] = padded_sequences_col1.tolist()\n",
    "df['description'] = padded_sequences_col2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "919b5b9f-fc5f-4381-bad7-96c63ec380ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 5, 2, 7, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 21, 3, 5, 2, 4, 13, 4, 8, 8, 17, 1, 1, 5, ...</td>\n",
       "      <td>0.535569</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 4, 19, 7, 7, 6, 7, 15, 1, 1, 9, 12, 8, 2, ...</td>\n",
       "      <td>[1, 11, 6, 15, 12, 5, 21, 2, 6, 15, 12, 5, 1, ...</td>\n",
       "      <td>-0.619322</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 20, 8, 15, 3, 1, 1, 14, 3, 5, 1, 1, 19, 7,...</td>\n",
       "      <td>[1, 2, 10, 8, 17, 4, 6, 2, 7, 16, 11, 20, 1, 1...</td>\n",
       "      <td>-0.235149</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 16, 6, 7, 6, 7, 15, 1, 1, 5, 3, 18, 11, 2,...</td>\n",
       "      <td>[1, 14, 8, 16, 2, 4, 7, 1, 1, 16, 6, 7, 6, 7, ...</td>\n",
       "      <td>0.700351</td>\n",
       "      <td>Furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 18, 11, 2, 7, 16, 2, 4, 1, 1, 13, 4, 2, 9,...</td>\n",
       "      <td>[1, 12, 6, 15, 12, 9, 13, 2, 2, 16, 1, 1, 18, ...</td>\n",
       "      <td>0.480648</td>\n",
       "      <td>Home Appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  [1, 5, 2, 7, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [1, 4, 19, 7, 7, 6, 7, 15, 1, 1, 9, 12, 8, 2, ...   \n",
       "2  [1, 20, 8, 15, 3, 1, 1, 14, 3, 5, 1, 1, 19, 7,...   \n",
       "3  [1, 16, 6, 7, 6, 7, 15, 1, 1, 5, 3, 18, 11, 2,...   \n",
       "4  [1, 18, 11, 2, 7, 16, 2, 4, 1, 1, 13, 4, 2, 9,...   \n",
       "\n",
       "                                         description     price  \\\n",
       "0  [1, 21, 3, 5, 2, 4, 13, 4, 8, 8, 17, 1, 1, 5, ...  0.535569   \n",
       "1  [1, 11, 6, 15, 12, 5, 21, 2, 6, 15, 12, 5, 1, ... -0.619322   \n",
       "2  [1, 2, 10, 8, 17, 4, 6, 2, 7, 16, 11, 20, 1, 1... -0.235149   \n",
       "3  [1, 14, 8, 16, 2, 4, 7, 1, 1, 16, 6, 7, 6, 7, ...  0.700351   \n",
       "4  [1, 12, 6, 15, 12, 9, 13, 2, 2, 16, 1, 1, 18, ...  0.480648   \n",
       "\n",
       "            category  \n",
       "0  Sports & Outdoors  \n",
       "1  Sports & Outdoors  \n",
       "2  Sports & Outdoors  \n",
       "3          Furniture  \n",
       "4    Home Appliances  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b91ac6-5df6-4d1c-9c65-2881abcd1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['category'] = label_encoder.fit_transform(df['category'])\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eff1774-d462-4d24-a21d-4328cc0216dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 10))\n",
    "df['price'] = scaler.fit_transform(df[['price']])\n",
    "df['combined'] = df.apply(lambda row: row['name'] + row['description'] + [int(row['price'])], axis=1)\n",
    "\n",
    "max_seq_length = max(df['combined'].apply(len))\n",
    "X = pad_sequences(df['combined'], maxlen=max_seq_length, padding='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7334d537-a3a0-49f8-9306-c0ad408c81bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Miniconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization, Embedding, LSTM, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=100, output_dim=50, input_length=max_seq_length),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Use 'categorical_crossentropy' for multiclass\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7b4057-538a-4db7-a157-2db33e9d86ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6584 - loss: 2.6218 - val_accuracy: 0.9631 - val_loss: 2.3680\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9617 - loss: 1.2987 - val_accuracy: 1.0000 - val_loss: 1.6704\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.8365 - val_accuracy: 1.0000 - val_loss: 1.3114\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.5606 - val_accuracy: 0.9975 - val_loss: 1.0387\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.3914 - val_accuracy: 1.0000 - val_loss: 0.7557\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.2760 - val_accuracy: 0.9906 - val_loss: 0.6159\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.1995 - val_accuracy: 1.0000 - val_loss: 0.4590\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.1540 - val_accuracy: 1.0000 - val_loss: 0.2668\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.1146 - val_accuracy: 1.0000 - val_loss: 0.1547\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0846 - val_accuracy: 0.9994 - val_loss: 0.2245\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,  # Adjust the number of epochs\n",
    "                    batch_size=128,  # Adjust the batch size\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20f9cae-cf98-4628-a4c2-0bf246916648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.2288\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.2333\n",
      "Training Loss: 0.22557556629180908, Training Accuracy: 0.9991250038146973\n",
      "Testing Loss: 0.2326909303665161, Testing Accuracy: 0.9980000257492065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train)\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}, Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Loss: {test_loss}, Testing Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e811f9f1-f0be-4925-bd87-efe2d6cbc973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion Matrix:\n",
      "[[391   0   0   0   0]\n",
      " [  0 402   0   0   0]\n",
      " [  0   0 405   0   0]\n",
      " [  1   0   3 399   0]\n",
      " [  0   0   0   0 399]]\n",
      "\n",
      "Classification Report:\n",
      "Target names: ['Electronics', 'Furniture', 'Home Appliances', 'Personal Care', 'Sports & Outdoors']\n",
      "Encoded Label -> Actual Category\n",
      "0 -> Electronics\n",
      "1 -> Furniture\n",
      "2 -> Home Appliances\n",
      "3 -> Personal Care\n",
      "4 -> Sports & Outdoors\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      Electronics       1.00      1.00      1.00       391\n",
      "        Furniture       1.00      1.00      1.00       402\n",
      "  Home Appliances       0.99      1.00      1.00       405\n",
      "    Personal Care       1.00      0.99      1.00       403\n",
      "Sports & Outdoors       1.00      1.00      1.00       399\n",
      "\n",
      "         accuracy                           1.00      2000\n",
      "        macro avg       1.00      1.00      1.00      2000\n",
      "     weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "target_names = list(map(str, label_encoder.classes_))\n",
    "print(\"Target names:\", target_names)  # Debugging line to verify target names\n",
    "\n",
    "print(\"Encoded Label -> Actual Category\")\n",
    "for encoded_label in range(len(label_encoder.classes_)):\n",
    "    actual_category = label_encoder.inverse_transform([encoded_label])\n",
    "    print(f\"{encoded_label} -> {actual_category[0]}\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df6c32c-1a7e-429d-a55f-701816068373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in d:\\programfiles\\miniconda\\lib\\site-packages (7.16.4)\n",
      "Requirement already satisfied: flake8 in d:\\programfiles\\miniconda\\lib\\site-packages (7.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (5.10.4)\n",
      "Requirement already satisfied: packaging in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (23.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (2.18.0)\n",
      "Requirement already satisfied: tinycss2 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (1.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert) (5.14.3)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from flake8) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from flake8) (2.11.1)\n",
      "Requirement already satisfied: pyflakes<3.3.0,>=3.2.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from flake8) (3.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: webencodings in d:\\programfiles\\miniconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (306)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbclient>=0.5.0->nbconvert) (8.6.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbformat>=5.7->nbconvert) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbformat>=5.7->nbconvert) (4.22.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\programfiles\\miniconda\\lib\\site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbconvert flake8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e77b36f-b47a-49d3-b8b8-3311fed8e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook payever_task.ipynb to script\n",
      "[NbConvertApp] Writing 9169 bytes to payever_task.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script payever_task.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6937a50-3205-480d-82f2-bd5e407204fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flake8 payever_task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452dd737-d110-48a8-af37-a0e0314af51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting docopt==0.6.2 (from pipreqs)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ipython==8.12.3 (from pipreqs)\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nbconvert<8.0.0,>=7.11.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from pipreqs) (7.16.4)\n",
      "Collecting yarg==0.1.9 (from pipreqs)\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting backcall (from ipython==8.12.3->pipreqs)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: decorator in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (0.1.7)\n",
      "Collecting pickleshare (from ipython==8.12.3->pipreqs)\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (2.18.0)\n",
      "Requirement already satisfied: stack-data in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (5.14.3)\n",
      "Requirement already satisfied: colorama in d:\\programfiles\\miniconda\\lib\\site-packages (from ipython==8.12.3->pipreqs) (0.4.6)\n",
      "Requirement already satisfied: requests in d:\\programfiles\\miniconda\\lib\\site-packages (from yarg==0.1.9->pipreqs) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.10.4)\n",
      "Requirement already satisfied: packaging in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (23.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.16.0)\n",
      "Requirement already satisfied: webencodings in d:\\programfiles\\miniconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in d:\\programfiles\\miniconda\\lib\\site-packages (from jedi>=0.16->ipython==8.12.3->pipreqs) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (306)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (8.6.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\programfiles\\miniconda\\lib\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.22.0)\n",
      "Requirement already satisfied: wcwidth in d:\\programfiles\\miniconda\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->pipreqs) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\programfiles\\miniconda\\lib\\site-packages (from beautifulsoup4->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programfiles\\miniconda\\lib\\site-packages (from requests->yarg==0.1.9->pipreqs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programfiles\\miniconda\\lib\\site-packages (from requests->yarg==0.1.9->pipreqs) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from requests->yarg==0.1.9->pipreqs) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programfiles\\miniconda\\lib\\site-packages (from requests->yarg==0.1.9->pipreqs) (2024.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from stack-data->ipython==8.12.3->pipreqs) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from stack-data->ipython==8.12.3->pipreqs) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in d:\\programfiles\\miniconda\\lib\\site-packages (from stack-data->ipython==8.12.3->pipreqs) (0.2.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\programfiles\\miniconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\programfiles\\miniconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (6.4)\n",
      "Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 41.0/798.3 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 225.3/798.3 kB 2.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 348.2/798.3 kB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 460.8/798.3 kB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 532.5/798.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 563.2/798.3 kB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 614.4/798.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 727.0/798.3 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.3/798.3 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13773 sha256=9ee38177923e82ecabc9b860cd5c0c400c244e0bc0c807fb796e6ab2e46503f2\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built docopt\n",
      "Installing collected packages: pickleshare, docopt, backcall, yarg, ipython, pipreqs\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.24.0\n",
      "    Uninstalling ipython-8.24.0:\n",
      "      Successfully uninstalled ipython-8.24.0\n",
      "Successfully installed backcall-0.2.0 docopt-0.6.2 ipython-8.12.3 pickleshare-0.7.5 pipreqs-0.5.0 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85269202-29f4-40e1-ad66-5c5293fd0f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Not scanning for jupyter notebooks.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"D:\\ProgramFiles\\Miniconda\\Scripts\\pipreqs.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"D:\\ProgramFiles\\Miniconda\\Lib\\site-packages\\pipreqs\\pipreqs.py\", line 609, in main\n",
      "    init(args)\n",
      "  File \"D:\\ProgramFiles\\Miniconda\\Lib\\site-packages\\pipreqs\\pipreqs.py\", line 599, in init\n",
      "    generate_requirements_file(path, imports, symbol)\n",
      "  File \"D:\\ProgramFiles\\Miniconda\\Lib\\site-packages\\pipreqs\\pipreqs.py\", line 209, in generate_requirements_file\n",
      "    with _open(path, \"w\") as out_file:\n",
      "  File \"D:\\ProgramFiles\\Miniconda\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"D:\\ProgramFiles\\Miniconda\\Lib\\site-packages\\pipreqs\\pipreqs.py\", line 91, in _open\n",
      "    file = open(filename, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\Rohan\\\\ML\\\\Projects\\\\Payever\\\\requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "!pipreqs . --use-local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29fc633-4079-4139-b09d-5ae02c18033d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
